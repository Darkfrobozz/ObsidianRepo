This is a master exams work made by Desiree björkman.

The work is based on the conversion between natural language and coding language by use of neural networks / machine learning.


Arbetet börjar med [[anledningen - coding without syntax]]. Det tillkänneger också att det är en typ av fortsättning på [[Byströms verk]].

Three methods from [[Machine Learning]] were used in the optimization of this previous work.

A more interesting take on this work is that it does not really see the bigger picture of what coding languages are, they are personalized. There is no reason to have different coding languages if some does not work better for distinct purposes and people. Therefore, what should be really tried is how to make a [[personalized programming language]], which is what is being shaped by the addition of open source libraries.

A representation of the structure can be seen in [[OverlayingStructureCwS_sketch]].


Research questions:

1. Is it possible to extend Byström’s system with automatized machine learning models? 
2. Is it possible to improve on Byström’s system by automatizing machine learning models.
3. If it could be classifiable as a learning tool for computational thinking or assist as a general programming tool.  
4. Is it a suitable tool for general programming?
5. Is LSTM a suitable model to this problem?  
6. Is there a more suitable solution/model?


Hypothesis: CNN should be able to interpret natural language to at least the same accuracy as traditional algorithms in machine learning for text classification.





